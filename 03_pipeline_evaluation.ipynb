{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, recall_score, f1_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataset/20_newgroups.xlsx')\n",
    "# this is a quick fixup for illegal characters\n",
    "df = df.applymap(lambda x: bytes(x, \"utf-8\").decode(\"unicode_escape\") if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['content'].astype(str).values\n",
    "y=df['target'].astype(str).values\n",
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8453380468404772"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred == y_test).sum() / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.96      0.90      0.93       100\n",
      "           comp.graphics       0.73      0.81      0.77       109\n",
      " comp.os.ms-windows.misc       0.89      0.26      0.40       123\n",
      "comp.sys.ibm.pc.hardware       0.55      0.80      0.65       116\n",
      "   comp.sys.mac.hardware       0.87      0.74      0.80       113\n",
      "          comp.windows.x       0.74      0.91      0.82       122\n",
      "            misc.forsale       0.85      0.63      0.73       104\n",
      "               rec.autos       0.86      0.94      0.90       109\n",
      "         rec.motorcycles       0.96      0.92      0.94       132\n",
      "      rec.sport.baseball       0.97      0.93      0.95       139\n",
      "        rec.sport.hockey       0.95      0.96      0.96       126\n",
      "               sci.crypt       0.86      0.96      0.90       123\n",
      "         sci.electronics       0.86      0.74      0.80       116\n",
      "                 sci.med       0.93      0.96      0.95       104\n",
      "               sci.space       0.89      0.96      0.92       112\n",
      "  soc.religion.christian       0.80      0.97      0.88       120\n",
      "      talk.politics.guns       0.82      0.95      0.88       104\n",
      "   talk.politics.mideast       0.95      0.96      0.96       130\n",
      "      talk.politics.misc       0.75      0.93      0.83        82\n",
      "      talk.religion.misc       0.96      0.61      0.74        79\n",
      "\n",
      "             avg / total       0.86      0.85      0.84      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8453380468404772"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In pattern recognition, information retrieval and binary classification, \n",
    "\n",
    "precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances, while \n",
    "\n",
    "recall (also known as sensitivity) is the fraction of relevant instances that have been retrieved over the total amount of relevant instances. \n",
    "Both precision and recall are therefore based on an understanding and measure of relevance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Other Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['content'].astype(str).values\n",
    "y=df['target'].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8453380468404772"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8435704816615113"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861246133451171"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df=0.8, ngram_range=(1, 2))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Other Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317719840919134"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df=0.8, ngram_range=(1, 2))),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Razvan\\AppData\\Local\\conda\\conda\\envs\\googleapi\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9186920017675652"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df=0.8, ngram_range=(1, 2))),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7551922227132125"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df=0.8, ngram_range=(1, 2))),\n",
    "    ('clf', KNeighborsClassifier())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.2, random_state=1235)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if the results we get are just due to a LUCKY or UNLUCKY train test split?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(clf, X, y, K):\n",
    "    cv = KFold(K, shuffle=True)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv, n_jobs=-1)\n",
    "    print(scores)\n",
    "    print(\"Mean score: {0:.3f} \".format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91021562 0.91728526 0.92149929 0.92149929]\n",
      "Mean score: 0.918 \n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect', TfidfVectorizer(min_df=5, max_df=0.8, ngram_range=(1, 2))),\n",
    "    ('clf', SGDClassifier())\n",
    "])\n",
    "evaluate_cross_validation(clf, X, y, 4)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Example of a big and complex Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    # Extract the subject & body\n",
    "    ('subjectbody', SubjectBodyExtractor()),\n",
    "\n",
    "    # Use FeatureUnion to combine the features from subject and body\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for pulling features from the post's subject line\n",
    "            ('subject', Pipeline([\n",
    "                ('selector', ItemSelector(key='subject')),\n",
    "                ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for standard bag-of-words model for body\n",
    "            ('body_bow', Pipeline([\n",
    "                ('selector', ItemSelector(key='body')),\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('best', TruncatedSVD(n_components=50)),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for pulling ad hoc features from post's body\n",
    "            ('body_stats', Pipeline([\n",
    "                ('selector', ItemSelector(key='body')),\n",
    "                ('stats', TextStats()),  # returns a list of dicts\n",
    "                ('vect', DictVectorizer()),  # list of dicts -> feature matrix\n",
    "            ])),\n",
    "\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'subject': 0.8,\n",
    "            'body_bow': 0.5,\n",
    "            'body_stats': 1.0,\n",
    "        },\n",
    "    )),\n",
    "\n",
    "    # Use a SVC classifier on the combined features\n",
    "    ('svc', SVC(kernel='linear')),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline (mix and match)\n",
    "multiple classifiers\n",
    "multiple features\n",
    "reports\n",
    "accuracy\n",
    "f1-score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
